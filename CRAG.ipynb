{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7357a9-a59b-4681-9062-dc30c96a7a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from helper_functions import encode_pdf\n",
    "import json\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c8eab1-ce95-4d03-8fc1-78a2cd482370",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\n",
    "    os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d605a26-b11e-44b6-a215-bd9038ef323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "from evaluation.rag_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00948bde-7465-4600-8ab0-851df726a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29f8e20-be6f-4fb4-bf48-280ea880dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Revathi\\Documents\\GenAIProjects\\All_RAG_Techniques\\data\\Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990c2b86-f450-43a3-9263-5a29044baf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d5fa34-5160-4446-822f-093a1dd40d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2105af77-8c19-4062-a770-9375b7383209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting click>=8.1.8 (from duckduckgo-search)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python312\\lib\\site-packages (from click>=8.1.8->duckduckgo-search) (0.4.6)\n",
      "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 2.6/4.0 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading primp-0.15.0-cp38-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.1 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.1/3.1 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.6/3.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: primp, lxml, click, duckduckgo-search\n",
      "\n",
      "   ---------------------------------------- 0/4 [primp]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [click]\n",
      "   -------------------- ------------------- 2/4 [click]\n",
      "   -------------------- ------------------- 2/4 [click]\n",
      "   -------------------- ------------------- 2/4 [click]\n",
      "   -------------------- ------------------- 2/4 [click]\n",
      "   -------------------- ------------------- 2/4 [click]\n",
      "   ------------------------------ --------- 3/4 [duckduckgo-search]\n",
      "   ------------------------------ --------- 3/4 [duckduckgo-search]\n",
      "   ------------------------------ --------- 3/4 [duckduckgo-search]\n",
      "   ------------------------------ --------- 3/4 [duckduckgo-search]\n",
      "   ---------------------------------------- 4/4 [duckduckgo-search]\n",
      "\n",
      "Successfully installed click-8.2.1 duckduckgo-search-8.1.1 lxml-6.0.0 primp-0.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5417f91-ad49-4e2a-8022-adb98a3f7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dab45ed5-f1f3-4756-8803-9360d7d6a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Evaluator\n",
    "class RetrievalEvaluatorInput(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
    "def retrieval_evaluator(query: str, document: str) -> float:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(RetrievalEvaluatorInput)\n",
    "    input_variables = {\"query\": query, \"document\": document}\n",
    "    result = chain.invoke(input_variables).relevance_score\n",
    "    return result\n",
    "\n",
    "# Knowledge Refinement\n",
    "class KnowledgeRefinementInput(BaseModel):\n",
    "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
    "def knowledge_refinement(document: str) -> List[str]:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"document\"],\n",
    "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(KnowledgeRefinementInput)\n",
    "    input_variables = {\"document\": document}\n",
    "    result = chain.invoke(input_variables).key_points\n",
    "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
    "\n",
    "# Web Search Query Rewriter\n",
    "class QueryRewriterInput(BaseModel):\n",
    "    query: str = Field(..., description=\"The query to rewrite.\")\n",
    "def rewrite_query(query: str) -> str:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(QueryRewriterInput)\n",
    "    input_variables = {\"query\": query}\n",
    "    return chain.invoke(input_variables).query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "939fcfc4-850c-4078-a7c0-3fdb73ac7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse a JSON string of search results into a list of title-link tuples.\n",
    "\n",
    "    Args:\n",
    "        results_string (str): A JSON-formatted string containing search results.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
    "                               If parsing fails, an empty list is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to parse the JSON string\n",
    "        results = json.loads(results_string)\n",
    "        # Extract and return the title and link from each result\n",
    "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle JSON decoding errors by returning an empty list\n",
    "        print(\"Error parsing search results. Returning empty list.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec811727-208c-4601-94b4-837490af6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on a query using a FAISS index.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for.\n",
    "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
    "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of the retrieved document contents.\n",
    "    \"\"\"\n",
    "    docs = faiss_index.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Evaluate the relevance of documents based on a query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "        documents (List[str]): A list of document contents to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: A list of relevance scores for each document.\n",
    "    \"\"\"\n",
    "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
    "\n",
    "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Perform a web search based on a query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[Tuple[str, str]]]: \n",
    "            - A list of refined knowledge obtained from the web search.\n",
    "            - A list of tuples containing titles and links of the sources.\n",
    "    \"\"\"\n",
    "    rewritten_query = rewrite_query(query)\n",
    "    web_results = search.run(rewritten_query)\n",
    "    web_knowledge = knowledge_refinement(web_results)\n",
    "    sources = parse_search_results(web_results)\n",
    "    return web_knowledge, sources\n",
    "\n",
    "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response to a query using knowledge and sources.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "        knowledge (str): The refined knowledge to use in the response.\n",
    "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "    \"\"\"\n",
    "    response_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
    "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
    "    )\n",
    "    input_variables = {\n",
    "        \"query\": query,\n",
    "        \"knowledge\": knowledge,\n",
    "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
    "    }\n",
    "    response_chain = response_prompt | llm\n",
    "    return response_chain.invoke(input_variables).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02e1f66c-c5f4-4276-9bd4-fa11b31e6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
    "    \"\"\"\n",
    "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to process.\n",
    "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response based on the query.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing query: {query}\")\n",
    "\n",
    "    # Retrieve and evaluate documents\n",
    "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
    "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
    "    print(f\"Evaluation scores: {eval_scores}\")\n",
    "\n",
    "    # Determine action based on evaluation scores\n",
    "    max_score = max(eval_scores)\n",
    "    sources = []\n",
    "        \n",
    "    if max_score > 0.7:\n",
    "        print(\"\\nAction: Correct - Using retrieved document\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        final_knowledge = best_doc\n",
    "        sources.append((\"Retrieved document\", \"\"))\n",
    "    elif max_score < 0.3:\n",
    "        print(\"\\nAction: Incorrect - Performing web search\")\n",
    "        final_knowledge, sources = perform_web_search(query)\n",
    "    else:\n",
    "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        # Refine the retrieved knowledge\n",
    "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
    "        web_knowledge, web_sources = perform_web_search(query)\n",
    "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
    "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
    "\n",
    "    print(\"\\nFinal knowledge:\")\n",
    "    print(final_knowledge)\n",
    "    \n",
    "    print(\"\\nSources:\")\n",
    "    for title, link in sources:\n",
    "        print(f\"{title}: {link}\" if link else title)\n",
    "\n",
    "    # Generate response\n",
    "    print(\"\\nGenerating response...\")\n",
    "    response = generate_response(query, final_knowledge, sources)\n",
    "\n",
    "    print(\"\\nResponse generated\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b4af987-5c25-4c84-9746-69aad34f00ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing query: What are the main causes of climate change?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved 3 documents\n",
      "Evaluation scores: [0.9, 0.9, 0.7]\n",
      "\n",
      "Action: Correct - Using retrieved document\n",
      "\n",
      "Final knowledge:\n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. \n",
      "Fossil Fuels \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today. \n",
      "Coal\n",
      "\n",
      "Sources:\n",
      "Retrieved document\n",
      "\n",
      "Generating response...\n",
      "\n",
      "Response generated\n",
      "Query: What are the main causes of climate change?\n",
      "Answer: The main causes of climate change primarily stem from the increase in greenhouse gases in the atmosphere, which are largely a result of human activities. Here are the key factors:\n",
      "\n",
      "1. **Greenhouse Gases**: The increase in greenhouse gases such as carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O) is the primary driver of recent climate change. These gases trap heat from the sun, creating a \"greenhouse effect\" that is essential for maintaining the Earth's temperature. However, human activities have significantly intensified this effect, leading to a rise in global temperatures.\n",
      "\n",
      "2. **Fossil Fuels**: The burning of fossil fuels (coal, oil, and natural gas) for energy is a major contributor to the increase in CO2 levels. This includes their use in electricity generation, heating, and transportation. The industrial revolution marked a significant rise in fossil fuel consumption, and this trend has continued, exacerbating climate change.\n",
      "\n",
      "3. **Coal**: As one of the primary fossil fuels, coal combustion releases substantial amounts of CO2 and other pollutants, further contributing to the greenhouse effect and climate change.\n",
      "\n",
      "These factors collectively lead to a warmer climate, impacting ecosystems, weather patterns, and sea levels.\n",
      "\n",
      "Sources: Retrieved document.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the main causes of climate change?\"\n",
    "result = crag_process(query, vectorstore)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b2f7d4c-2b9b-4bdf-b8ce-fe6d9bd6319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing query: how did harry beat quirrell?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved 3 documents\n",
      "Evaluation scores: [0.0, 0.0, 0.0]\n",
      "\n",
      "Action: Incorrect - Performing web search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\Revathi\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1759: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing search results. Returning empty list.\n",
      "\n",
      "Final knowledge:\n",
      "['- 译者翻译文章因作者开放转载权限', '- 文章讨论DID（多重人格障碍）患者大脑变化', '- 研究结果虽不惊人，但引用全面', '- DID-IV方法可用于特定条件下的安慰剂检测', '- 双重差分结合工具变量法（DID-IV）是成熟计量方法', '- 双重差分法（DID）本身不解决内生性问题', '- 双重差分法依赖于干预或政策冲击的外生性', '- 标准DID形式存在', '- done常用于完成时态的句子中', '- done与did在用法上有时态和含义的不同']\n",
      "\n",
      "Sources:\n",
      "\n",
      "Generating response...\n",
      "\n",
      "Response generated\n",
      "Query: how did harry beat quirrell?\n",
      "Answer: In \"Harry Potter and the Sorcerer's Stone,\" Harry Potter defeats Professor Quirrell, who is possessed by Voldemort, through a combination of bravery and the protective magic of his mother's sacrifice. When Harry confronts Quirrell in the underground chamber, he touches Quirrell's face, which causes Quirrell immense pain and ultimately leads to his defeat. This is because Quirrell cannot touch Harry without suffering severe consequences due to the love and protection that Harry's mother bestowed upon him when she sacrificed her life to save him from Voldemort.\n",
      "\n",
      "Sources:\n",
      "1. J.K. Rowling, \"Harry Potter and the Sorcerer's Stone\" - [Link to book](https://www.pottermore.com/writing-by-jk-rowling) (Note: This is a general link to Pottermore, as the book itself is not available for free online).\n"
     ]
    }
   ],
   "source": [
    "query = \"how did harry beat quirrell?\"\n",
    "result = crag_process(query, vectorstore)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b6264-6663-4de8-b4c5-6c1df60d5924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
